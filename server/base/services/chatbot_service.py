# ì±—ë´‡ì´ ì°¸ê³ í•  ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤(Vector DB)ë¥¼ ë§Œë“¤ê³  ê´€ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ ëª¨ë“ˆ
# - Markdown ë¬¸ì„œë¥¼ ì½ì–´ì„œ ë²¡í„°í™”(ì„ë² ë”©)í•˜ê³ 
# - ë©”ëª¨ë¦¬ ê¸°ë°˜ Chroma DBì— ì €ì¥í•˜ì—¬
# - ì±—ë´‡ ì§ˆì˜ ì‹œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ì— í™œìš©í•œë‹¤.

import os
from pathlib import Path
from langchain.text_splitter import MarkdownHeaderTextSplitter
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.schema import Document
from django.conf import settings
import logging

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# Django í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(settings.BASE_DIR)
DOCS_PATH = BASE_DIR / "docs"

# ì „ì—­ ë²¡í„°DB ì¸ìŠ¤í„´ìŠ¤ (ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥)
_vectordb_instance = None
_is_initialized = False

def check_docs_folder():
    """
    ğŸ“Œ docs í´ë”ì™€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    - í´ë”ê°€ ì—†ê±°ë‚˜ md íŒŒì¼ì´ ì—†ìœ¼ë©´ False ë°˜í™˜
    - ì •ìƒì¸ ê²½ìš° ë°œê²¬ëœ md íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë°˜í™˜
    """
    if not DOCS_PATH.exists():
        logger.error(f"âŒ Docs í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {DOCS_PATH}")
        return False, []
    
    md_files = list(DOCS_PATH.glob("*.md"))
    if not md_files:
        logger.error(f"âŒ {DOCS_PATH}ì— .md íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        return False, []
    
    logger.info(f"âœ… ë°œê²¬ëœ MD íŒŒì¼ë“¤: {[f.name for f in md_files]}")
    return True, md_files

def build_vector_db(force_rebuild=False):
    """
    ğŸ“Œ .md íŒŒì¼ë“¤ì„ ì½ì–´ì„œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„°DBë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    - Markdown ë¬¸ì„œë¥¼ í—¤ë” ë‹¨ìœ„(#, ##, ###)ë¡œ ìª¼ê°¬
    - ì¡°ê°ì„ Document ê°ì²´ë¡œ ë³€í™˜í•˜ê³  ë©”íƒ€ë°ì´í„°(source, chunk_id, headers) ë¶€ì—¬
    - OpenAI Embeddingsìœ¼ë¡œ ë²¡í„°í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ê¸°ë°˜ Chroma DB ìƒì„±
    """
    global _vectordb_instance, _is_initialized
    
    # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆê³  ê°•ì œ ì¬ë¹Œë“œê°€ ì•„ë‹ˆë©´ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    if _is_initialized and not force_rebuild:
        logger.info("âœ… ê¸°ì¡´ ë©”ëª¨ë¦¬ ë²¡í„°DB ì‚¬ìš©")
        return _vectordb_instance
    
    # docs í´ë”ì™€ md íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    folder_exists, md_files = check_docs_folder()
    if not folder_exists:
        raise FileNotFoundError(f"Docs í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DOCS_PATH}")
    
    docs = []
    splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=[
            ("#", "header1"),
            ("##", "header2"),
            ("###", "header3"),
        ]
    )
    
    # ê° md íŒŒì¼ì„ ì½ì–´ì„œ ë¶„í•  â†’ Document ê°ì²´ë¡œ ë³€í™˜
    for file_path in md_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()
            
            if not text.strip():
                logger.warning(f"âš ï¸ ë¹ˆ íŒŒì¼: {file_path.name}")
                continue
            
            split_docs = splitter.split_text(text) # í—¤ë” ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ ë¶„ë¦¬
            for i, doc in enumerate(split_docs):
                if isinstance(doc, str): # ë¬¸ìì—´ì¸ ê²½ìš°ì™€ Document ê°ì²´ì¸ ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
                    content = doc
                    metadata = {
                        "source": file_path.name, # ì¶œì²˜ íŒŒì¼ëª…
                        "chunk_id": i # ì¡°ê° ë²ˆí˜¸
                    }
                else:
                    content = doc.page_content if hasattr(doc, 'page_content') else str(doc)
                    metadata = { # ë©”íƒ€ë°ì´í„°ë¥¼ ë‹¨ìˆœí•œ í˜•íƒœë¡œ ë³€í™˜
                        "source": file_path.name,
                        "chunk_id": i
                    }
                    if hasattr(doc, 'metadata') and 'headers' in doc.metadata: # Document.metadataì— headersê°€ ìˆìœ¼ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
                        headers = doc.metadata.get('headers', {})
                        if headers:
                            header_str = ", ".join([f"{k}: {v}" for k, v in headers.items() if v]) # ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                            if header_str:
                                metadata["headers"] = header_str
                
                docs.append(Document( # LangChain Document ê°ì²´ ìƒì„±
                    page_content=content,
                    metadata=metadata
                ))
            
            logger.info(f"âœ… {file_path.name} ì²˜ë¦¬ ì™„ë£Œ ({len(split_docs)}ê°œ ì²­í¬)")
            
        except Exception as e:
            logger.error(f"âŒ {file_path.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    if not docs:
        raise ValueError("ì²˜ë¦¬ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. MD íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    logger.info(f"ğŸ“Š ì´ {len(docs)}ê°œì˜ ë¬¸ì„œ ì²­í¬ ìƒì„±")
    
    # OpenAI ì„ë² ë”©ì„ ì´ìš©í•´ ë©”ëª¨ë¦¬ ê¸°ë°˜ Chroma DB ìƒì„±
    try:
        embeddings = OpenAIEmbeddings(api_key=settings.OPENAI_API_KEY)
        
        # ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ (íŒŒì¼ ì‹œìŠ¤í…œ ì‚¬ìš© ì•ˆ í•¨)
        _vectordb_instance = Chroma.from_documents(
            documents=docs,
            embedding=embeddings
            # persist_directory ì œê±° - ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥
        )
        
        _is_initialized = True
        logger.info("âœ… ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„°DB ìƒì„± ì™„ë£Œ")
        return _vectordb_instance
        
    except Exception as e:
        logger.error(f"âŒ ë²¡í„°DB ìƒì„± ì‹¤íŒ¨: {e}")
        _vectordb_instance = None
        _is_initialized = False
        raise

def get_vector_db():
    """
    ğŸ“Œ ë²¡í„°DB ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    - ì´ë¯¸ ì´ˆê¸°í™”ëœ DBê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    - ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬´íš¨í™”ë˜ë©´ build_vector_db()ë¡œ ìƒˆë¡œ ìƒì„±
    """
    global _vectordb_instance, _is_initialized
    
    # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë©´ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    if _is_initialized and _vectordb_instance:
        try:
            _vectordb_instance._collection.count() # ê°„ë‹¨í•œ ê²€ì¦ (DB ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€)
            return _vectordb_instance
        except:
            logger.warning("âš ï¸ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ë¬´íš¨, ì¬ìƒì„±")
            _is_initialized = False
    
    # ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    logger.info("ğŸ“‚ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„°DB ì´ˆê¸°í™” ì¤‘...")
    return build_vector_db()