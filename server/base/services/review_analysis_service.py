from transformers import AutoTokenizer, AutoModelForSequenceClassification
from collections import Counter
import torch
import re
import logging
from typing import List, Dict, Any
from django.conf import settings

# ë¡œê¹… ì„¤ì •
logging.getLogger("transformers").setLevel(logging.WARNING)

class HuggingFaceReviewAnalysisService:
    """Hugging Face ê¸°ë°˜ ë¦¬ë·° AI ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.sentiment_model = None
        self.sentiment_tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_models()
    
    def _initialize_models(self):
        """Hugging Face ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        try:
            print("ğŸ¤— Hugging Face ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # í•œêµ­ì–´ ê°ì •ë¶„ì„ ëª¨ë¸
            model_name = "alsgyu/sentiment-analysis-fine-tuned-model"
            
            self.sentiment_tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.sentiment_model = AutoModelForSequenceClassification.from_pretrained(model_name)
            
            if self.device == "cuda":
                self.sentiment_model = self.sentiment_model.to(self.device)
                print(f"âœ… GPU ëª¨ë“œë¡œ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            else:
                print("âœ… CPU ëª¨ë“œë¡œ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            # í´ë°±: í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ë§Œ ì‚¬ìš©
            self.sentiment_model = None
            self.sentiment_tokenizer = None

    def analyze_reviews(self, reviews_data: List[Dict]) -> Dict[str, Any]:
        """
        ë¦¬ë·° ë¶„ì„ (3ê°€ì§€ ê¸°ëŠ¥)
        reviews_data: [{'comment': str, 'rating': int}, ...]
        """
        if not reviews_data:
            raise ValueError("ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        comments = [review['comment'] for review in reviews_data]
        
        # 1. Hugging Face ê°ì • ë¶„ì„
        sentiment_analysis = self._analyze_sentiment_with_hf(comments)
        
        # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(comments)
        
        # 3. ê°„ë‹¨í•œ ìš”ì•½
        summary = self._generate_simple_summary(comments, sentiment_analysis)
        
        return {
            'sentiment_analysis': sentiment_analysis,
            'keywords': keywords,
            'summary': summary,
            'total_reviews': len(reviews_data)
        }

    def _analyze_sentiment_with_hf(self, comments: List[str]) -> Dict[str, float]:
        """Hugging Face ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°ì • ë¶„ì„"""
        
        if not self.sentiment_model:
            print("âš ï¸ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ ì‚¬ìš©")
            return self._fallback_sentiment_analysis(comments)
        
        try:
            print(f"ğŸ” {len(comments)}ê°œ ë¦¬ë·° ê°ì • ë¶„ì„ ì¤‘...")
            
            # ë°°ì¹˜ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
            batch_size = 8
            all_predictions = []
            
            for i in range(0, len(comments), batch_size):
                batch_comments = comments[i:i + batch_size]
                
                # í† í¬ë‚˜ì´ì§•
                inputs = self.sentiment_tokenizer(
                    batch_comments,
                    return_tensors="pt",
                    truncation=True,
                    padding=True,
                    max_length=512
                )
                
                if self.device == "cuda":
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # ì˜ˆì¸¡
                with torch.no_grad():
                    outputs = self.sentiment_model(**inputs)
                    predictions = torch.argmax(outputs.logits, dim=-1)
                    all_predictions.extend(predictions.cpu().tolist())
            
            # ê°ì • ë¶„ë¥˜ ì¹´ìš´íŠ¸
            label_counts = Counter(all_predictions)
            total = len(all_predictions)
            
            # ë ˆì´ë¸” ë§¤í•‘ (0: ë¶€ì •, 1: ì¤‘ë¦½, 2: ê¸ì •)
            negative = label_counts.get(0, 0)
            neutral = label_counts.get(1, 0)
            positive = label_counts.get(2, 0)
            
            return {
                'positive': round(positive / total * 100, 1),
                'negative': round(negative / total * 100, 1),
                'neutral': round(neutral / total * 100, 1)
            }
            
        except Exception as e:
            print(f"âŒ Hugging Face ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._fallback_sentiment_analysis(comments)

    def _fallback_sentiment_analysis(self, comments: List[str]) -> Dict[str, float]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ê°ì • ë¶„ì„"""
        positive_keywords = ['ì¢‹ì•„ìš”', 'ë§Œì¡±', 'ì¶”ì²œ', 'í›Œë¥­', 'ìµœê³ ', 'ê´œì°®', 'ì™„ë²½']
        negative_keywords = ['ë³„ë¡œ', 'ì‹¤ë§', 'ë‚˜ë¹ ìš”', 'ìµœì•…', 'ë¶ˆë§Œ', 'ë¬¸ì œ', 'í›„íšŒ']
        
        positive_count = 0
        negative_count = 0
        
        for comment in comments:
            comment_lower = comment.lower()
            if any(keyword in comment_lower for keyword in positive_keywords):
                positive_count += 1
            elif any(keyword in comment_lower for keyword in negative_keywords):
                negative_count += 1
        
        total = len(comments)
        neutral_count = total - positive_count - negative_count
        
        return {
            'positive': round(positive_count / total * 100, 1),
            'negative': round(negative_count / total * 100, 1),
            'neutral': round(neutral_count / total * 100, 1)
        }

    def _extract_keywords(self, comments: List[str]) -> List[tuple]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        all_text = ' '.join(comments).lower()
        
        # ë¶ˆìš©ì–´
        stop_words = {
            'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì˜', 'ëŠ”', 'ì€',
            'ì •ë§', 'ë„ˆë¬´', 'ì§„ì§œ', 'ì™„ì „', 'ì•„ì£¼', 'ë§¤ìš°', 'ì¡°ê¸ˆ', 'ì¢€', 'ê·¸ëƒ¥',
            'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ê·¸ë˜ì„œ', 'ë˜í•œ',
            'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ë˜', 'í•œ', 'ë‹¤', 'ë•Œ', 'ê³³'
        }
        
        # í•œê¸€ ë‹¨ì–´ ì¶”ì¶œ (2-6ì)
        words = re.findall(r'[ê°€-í£]{2,6}', all_text)
        filtered_words = [word for word in words if word not in stop_words]
        
        return Counter(filtered_words).most_common(10)

    def _generate_simple_summary(self, comments: List[str], sentiment: Dict[str, float]) -> str:
        """ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±"""
        total_reviews = len(comments)
        keywords = self._extract_keywords(comments)
        top_keywords = [word for word, count in keywords[:3]]
        
        # 3ì¤„ ìš”ì•½
        line1 = f"ì´ {total_reviews}ê°œ ë¦¬ë·°ì—ì„œ {', '.join(top_keywords)} ë“±ì´ ì£¼ìš” ê´€ì‹¬ì‚¬ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤." if top_keywords else f"ì´ {total_reviews}ê°œì˜ ê³ ê° ë¦¬ë·°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤."
        
        if sentiment['positive'] > 60:
            line2 = "ëŒ€ë¶€ë¶„ì˜ ê³ ê°ë“¤ì´ ê¸ì •ì ì¸ í‰ê°€ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤."
        elif sentiment['negative'] > 30:
            line2 = "ì¼ë¶€ ê³ ê°ë“¤ì´ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ì§€ì í•˜ê³  ìˆìŠµë‹ˆë‹¤."
        else:
            line2 = "ê³ ê°ë“¤ì˜ ì˜ê²¬ì´ ë‹¤ì–‘í•˜ê²Œ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤."
        
        if sentiment['positive'] > sentiment['negative']:
            line3 = "ì „ë°˜ì ìœ¼ë¡œ ë§Œì¡±ë„ê°€ ë†’ì€ ìƒí’ˆìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤."
        else:
            line3 = "êµ¬ë§¤ ì „ ìƒì„¸í•œ ë¦¬ë·° ê²€í† ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
        
        return f"{line1}\n{line2}\n{line3}"


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_analysis_service_instance = None

def get_review_analysis_service() -> HuggingFaceReviewAnalysisService:
    """ë¦¬ë·° ë¶„ì„ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    global _analysis_service_instance
    
    if _analysis_service_instance is None:
        _analysis_service_instance = HuggingFaceReviewAnalysisService()
    
    return _analysis_service_instance